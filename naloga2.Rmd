---
title: "naloga2-Nagelj"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  prettydoc::html_pretty:
    theme: architect
    toc: yes
   # toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(randomForest)
library(caret)
library(DataExplorer)
library(rpart)
library(dplyr)
library(car)
library(psych)
library(ROCR)
```
# UVOD
Z zbranimi podatki želimo napovedati ali ima določen pacient prisotno bolezen srca. Za ta klasifikacijski problem bomo primerjali tri različne metode: KNN, logistična regresija in odločitvena drevesa.

# METODOLOGIJA
Pri vsaki metodi bomo najprej na učnih podatkih s pomočjo prečnega preverjanja poiskali najboljšo kombinacijo spremenljivk in parametrov. Za to bomo uporabili metriko accuracy. Nato bomo na testnih podatkih s pomočjo metrike accuracy in auc med sebor primerjali metode. 

# PODATKI
```{r, echo=FALSE}
# PREPROCESSING 
data <- data.table(read.csv("./data/heart.csv"))
colnames(data)[1] <- 'age'

sum(complete.cases(data))/nrow(data)

# train/test split
set.seed(23)
train.index <- createDataPartition(data$target, p = 0.8, list = FALSE)

# varible types
label <- 'target'
cat <- c('target', 'sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')
num <- colnames(data)[!colnames(data) %in% cat]

# popravimo v factor
data.factor <- cbind(data[, ..num], 
                     data[, ..cat][, lapply(.SD, as.factor)])

cat <- cat[-1]

# train
train <- data.factor[train.index, ]

# test
test <- data.factor[-train.index, ]

# SCALE
train.scaled.num <- scale(train[, ..num])
train.scaled <- cbind(train.scaled.num, train[, ..cat], train[, ..label])

means <- attr(train.scaled.num, "scaled:center")
std <- attr(train.scaled.num, "scaled:scale")

test.scaled.num <- scale(test[, ..num], center = means, scale = std)
test.scaled <- cbind(test.scaled.num, test[, ..cat], test[, ..label])
```


Najprej sem preveril ali so prisotne manjkajoče vrednosti, teh ni bilo. Nato sem definiral katere spremenljivke so kategoricne in numerične. Naša odvisna spremenljivka oziroma razred je target. Podatke razdelimo na učno (243) in testno množico (60), kjer je 80% podatov v učni. 

Podatke si ogledamo le na učnem delu podatkov.
```{r, echo=FALSE}
str(train)
describe(train)
```
Imamo 13 atributov, od tega 5 numeričnih in 8 kategoričnih. Za modeliranje kategorični spremenljivk v R-ju je te potrebno definirati kot faktor. Predvsem nam v oči pade oldpeak kjer vidimo da je standardna deviacija precej velika glede na povprečje.

 
```{r, echo=FALSE}
# visulisation
plot_histogram(data[train.index, ], binary_as_factor = FALSE)
plot_density(data[train.index, ..num])
plot_correlation(data[train.index, -..label])
```

Vidimo, da sta obe vrednosti odvisne spremenljivke target zastopani približno enakomerno. Vse spremenljivke so porazdeljene približnost normalno. Ponovno nam v oči pade oldpeak kjer je zelo velika koncentracija pri vrednosti 0. Nekoliko večje korelacije so med slope in oldpeak in thalach z exang, oldpeak and slope. Vecja korelacije je tudi med thalach in age. Pričakujemo da oldpeak ne bo ena izmed izbranih spremenljivk, saj je močno kolerirani z nekaterimi drugimi, prav tako je pa zelo variabilna.

# IZBIRA MODELA S PREČNIM PREVERJANJEM
Za metriko bomo uporabili accuracy, torej delež pravilno klasicifiranih enot. Najprej si ogledamo baseline accuracy, nato pa s pomočjo prečnega preverjanja določimo najboljši napovedni model z iskanjem najboljše kombinacije neodvisnih spremenljivk in parametrov. Odločil sem se, da bom pri modelu KNN dodatno gledal parameter števila sosedov k, pri klasifikacijskih drevesih pa parameter maksimalne globine. Vsi numerični podatki v modelih so sklalirani.

## Baseline
Na testnih podatkih je delež enot z izzidom 1 enak: ```r round(sum(as.numeric(train$target) - 1) / length(train$target), 2) ```. Torej če bi za vsako enoto napovedovali brez kakršnih koli informacij bi dogodek napovedali s to verjetnostjo. Naš cilj izdelati boljši model.

## Prečno preverjanje
Najprej definiramo vse možne kombinacije spremenljivk. Izbrali bomo nekoliko bolj robustno metodo in preverili vse možne kombinacije. Za vsako kombinacijo bomo izvedli k-fold cross validation z delitvijo na 10 delov. Torej na 9 delih model naučimo in nato zadnjem, neuporabljenem delu ocenimo točnsot modela.
```{r, echo=FALSE}
methods <- c('knn', 'glm', 'rpart2')
train.control <- trainControl(method = "repeatedcv",
                              number = 10,
                              savePredictions = TRUE,
                              repeats = 10)
#  features <- colnames(X.train)
#  n = length(features)
#  x = 1:n
#  
#  comb <- NULL
#  for (i in 1:n) {
#      if (i == 1) {
#          for (j in 1:n) {
#            comb <- rbind(comb,  paste("target~", features[j]))
#          }
#      }
#      else {
#          for (j in 1:(n - i + 1)) {
#              for (k in (j + i - 1):n) {
#                comb <- rbind(comb, paste("target~", paste(c(features[j:(j + i - 2)], features[k]), collapse="+")))
#                  
#              }
#          }
#      }
#  }
#  
#  RunModel <- function(formula, data, method, control) {
#    model <- train(as.formula(formula), 
#                 data = data, 
#                 method = method,
#                 trControl = control)
#    #browser()
#    model$results
#  }
#  
#  SelectFeatures <- function(method, comb, data, control) {
#    featureSelection <- NULL
#    for (c in comb) {
#      m <- RunModel(formula = c, data = data, method = method, control = control)
#      featureSelection <- rbind(featureSelection, cbind(c, m))
#    }
#    featureSelection
#  }
#  
#  
#  
#  selection <- lapply(methods, SelectFeatures, data = train.scaled, comb = comb, control = train.control)
#  saveRDS(selection, "selection.rds")
```

```{r, echo=FALSE}
selection <- readRDS("selection.rds")
for (i in 1:3) {
  sel <- selection[[i]]
  print(methods[i])
  print(sel[order(-sel$Accuracy),][1:5,])
}
```
# IZBIRA MODELA S PREČNIM PREVERJANJEM
Za izbiro nabora spremenljivk obstajata dve skupini metod: wrapper in filter. Wrapper metode vrednotijo napovedni model z različnimi kombinacijami spremenljivk in s tem maksimizirajo model glede na določeno metriko (recursive feature elimination, genetic algorithms). Filter metode pa ocenijo relevantnost posameznih spremenljivk brez napovednega modela na podlagi izbranih kriterijev (univariatni filtri). Saj je naš cilj izbrati čimbolj efektiven in točen model, se bomo poslužili prve metode. 

```{r}
# TODO feature elimination
#http://topepo.github.io/caret/recursive-feature-elimination.html
```


metriko bomo uporabili accuracy, torej delež pravilno klasicifiranih enot. Najprej si ogledamo baseline accuracy, nato pa s pomočjo prečnega preverjanja določimo najboljši napovedni model z iskanjem najboljše kombinacije neodvisnih spremenljivk in parametrov. Odločil sem se, da bom pri modelu KNN dodatno gledal parameter števila sosedov k, pri klasifikacijskih drevesih pa parameter maksimalne globine. Vsi numerični podatki v modelih so sklalirani.

## Baseline
Na testnih podatkih je delež enot z izzidom 1 enak: ```r round(sum(as.numeric(train$target) - 1) / length(train$target), 2) ```. Torej če bi za vsako enoto napovedovali brez kakršnih koli informacij bi dogodek napovedali s to verjetnostjo. Naš cilj izdelati boljši model.

## Prečno preverjanje
Najprej definiramo vse možne kombinacije spremenljivk. Izbrali bomo nekoliko bolj robustno metodo in preverili vse možne kombinacije. Za vsako kombinacijo bomo izvedli k-fold cross validation z delitvijo na 10 delov. Torej na 9 delih model naučimo in nato zadnjem, neuporabljenem delu ocenimo točnsot modela.


## Izbran model
Izbrali bomo le najboljše izmed modelov glede na metodo.
```{r, echo=FALSE}
selected.models <- NULL
for (i in 1:3) {
  sel <- selection[[i]]
  sel.model <- cbind(methods[i], sel[order(-sel$Accuracy),][1,])
  colnames(sel.model) <- c('method', 'formula', 'parameter', "Accuracy", "Kappa", "AccuracySD", "KappaSD")
  selected.models <- rbind(selected.models, sel.model)
  
}
selected.models
```
Vidimo, da logistična regresija doseže najvejčo točnost in pri tem uporabi 8 od 13 atributov, met tem ko knn doseže za 1% manjšo točnost z uporabo le 6 atributov. Če primerjamo prej omenjena modela so jima skupne spremenljivke  cp, fbs, restecg, exang in slope. Dodatne spremenljivke, ki se pojavijo v modelu z odločitvenim drevesom pa so age, trestbps, chol in thalach. Torej preseka med spremenljivkami vseh treh modelov ni.

## Ocenjevanje modelov na testnih podatkih
```{r, echo=FALSE}
# IZBRANI MODELI
knn <- train(as.formula(as.character(selected.models[1, 2])),
             data = train, 
             method = selected.models[1, 1],
             trControl = train.control)

log <- train(as.formula(as.character(selected.models[2, 2])),
             data = train, 
             method = selected.models[2, 1],
             trControl = train.control)

tree <- train(as.formula(as.character(selected.models[3, 2])),
             data = train, 
             method = selected.models[3, 1],
             trControl = train.control)
```


```{r}
ggplot(knn) + theme_minimal()
ggplot(tree) + theme_minimal()
```


```{r}
# TODO plot drevesa
```



```{r, echo=FALSE}
# ODSTRANJENO ZARADI SPODNJE KODE
## NAPOVEDI
#y.hat <- matrix(NA, nrow = 60, 3)
#y.hat[, 1] <- predict(knn, newdata = test.scaled, type = 'prob')[, 2]
#y.hat[, 2]<- predict(log, newdata = test.scaled, type = 'prob')[, 2]
#y.hat[, 3] <- predict(tree, newdata = test.scaled, type = 'prob')[, 1]
#
## METRIKE
#metrike <- NULL
#for (i in 1:3) {
#  pred <- prediction(y.hat[, i], test$target)
#  auc <- round(as.numeric(performance(pred, "auc")@y.values), 3)
#  acc <- round(sum(round(y.hat[, i]) == test$target) / length(test$target), 3)
#  metrike <- rbind(metrike, cbind(methods[i], auc, acc))
#}
#metrike[3, 'auc'] <- 1-as.numeric(metrike[3, 'auc'])
#metrike <- data.frame(metrike)
#colnames(metrike)[1] <- 'metoda'
#
#metrike
```


```{r}
# TODO uredi kodo
confusionMatrix(data = predict(knn, newdata = test.scaled), reference = test.scaled$target)
confusionMatrix(data = predict(log, newdata = test.scaled), reference = test.scaled$target)
confusionMatrix(data = predict(tree, newdata = test.scaled), reference = test.scaled$target)
```
Vidimo da glm model deluje najbolje tudi na testnih podatkih, med tem ko je odločitveno drevo preveč preprilegano na učnih podatkih. Odločili bi se za model z logistično regresijo, saj je boljši tudi od modela KNN.


## Pomembnost spremenljivk
```{r}
# TODO za najboljši model
varImp(knn)
plot(gbmImp, top = 20)
```